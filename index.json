[{"authors":["admin"],"categories":null,"content":"ZHANG Hao is a research engineer of Artificial Intelligence Initiative (A*AI) at Agency for Science, Technology and Research (A*STAR), Singapore. His research interests include natural language processing, visual grounding, reinforcement learning for robotics and machine learning methods.\nMeanwhile, ZHANG Hao is pursuing his Ph.D. in computer science at Nayang Technological University (NTU) since Aug. 2019, and he is supervised by Associate Prof. SUN Aixin.\nWHAT I KNOW\nProgramming Languages: Python, Java, C/C++, JavaScript.\nTools \u0026amp; Frameworks: TensorFlow, PyTorch, Keras, DL4J, Stanford NLP, Spark, ConceptNet, Neo4J and etc.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"ZHANG Hao is a research engineer of Artificial Intelligence Initiative (A*AI) at Agency for Science, Technology and Research (A*STAR), Singapore. His research interests include natural language processing, visual grounding, reinforcement learning for robotics and machine learning methods.\nMeanwhile, ZHANG Hao is pursuing his Ph.D. in computer science at Nayang Technological University (NTU) since Aug. 2019, and he is supervised by Associate Prof. SUN Aixin.\nWHAT I KNOW\nProgramming Languages: Python, Java, C/C++, JavaScript.","tags":null,"title":"ZHANG Hao","type":"authors"},{"authors":["Tianying Wang*","Wei Qi Toh*","Hao Zhang*","Xiuchao Sui","Shaohua Li","Yong Liu","Wei Jing"],"categories":null,"content":"","date":1581033600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581033600,"objectID":"27c876932774e513bc2d0762f1067e33","permalink":"/publication/robocodraw/","publishdate":"2020-02-15T00:00:00Z","relpermalink":"/publication/robocodraw/","section":"publication","summary":"Robotic drawing has become increasingly popular as an entertainment and interactive tool. In this paper we present RoboCoDraw, a real-time collaborative robot-based drawing system that draws stylized human face sketches interactively in front of human users, by using the Generative Adversarial Network (GAN)-based style transfer and a Random-Key Genetic Algorithm (RKGA)-based path optimization. The proposed RoboCoDraw system takes a real human face image as input, converts it to a stylized avatar, then draws it with a robotic arm. A core component in this system is the Avatar-GAN proposed by us, which generates a cartoon avatar face image from a real human face. AvatarGAN is trained with unpaired face and avatar images only and can generate avatar images of much better likeness with human face images in comparison with the vanilla CycleGAN. After the avatar image is generated, it is fed to a line extraction algorithm and converted to sketches. An RKGA-based path optimization algorithm is applied to find a time-efficient robotic drawing path to be executed by the robotic arm. We demonstrate the capability of RoboCoDraw on various face images using a lightweight, safe collaborative robot UR5.","tags":null,"title":"RoboCoDraw: Robotic Avatar Drawing with GAN-based Style Transfer and Time-efficient Path Optimization","type":"publication"},{"authors":["Tianying Wang","Hao Zhang","Wei Qi Toh","Hongyuan Zhu","Cheston Tan","Yan Wu","Yong Liu","Wei Jing"],"categories":null,"content":"","date":1575590400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575590400,"objectID":"409102bf0ed4b329fd29259c3e1faf4d","permalink":"/publication/deep-model-fusion/","publishdate":"2019-12-06T00:00:00Z","relpermalink":"/publication/deep-model-fusion/","section":"publication","summary":"Learning-based methods have been used to program robotic tasks in recent years. However, extensive training is usually required not only for the initial task learning but also for generalizing the learned model to the same task but in different environments. In this paper, we propose a novel Deep Reinforcement Learning algorithm for efficient task generalization and environment adaptation in the robotic task learning problem. The proposed method is able to efficiently generalize the previously learned task by model fusion to solve the environment adaptation problem. The proposed Deep Model Fusion (DMF) method reuses and combines the previously trained model to improve the learning efficiency and results. Besides, we also introduce a Multi-objective Guided Reward (MGR) shaping technique to further improve training efficiency. The proposed method was benchmarked with previous methods in various environments to validate its effectiveness.","tags":null,"title":"Efficient Robotic Task Generalization Using Deep Model Fusion Reinforcement Learning","type":"publication"},{"authors":["Joey Tianyi Zhou*","Hao Zhang*","Di Jing","Xi Peng"],"categories":null,"content":"","date":1564531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564531200,"objectID":"9f2b298f60364c5452911293fdb512a4","permalink":"/publication/datnet-tpami/","publishdate":"2019-07-31T00:00:00Z","relpermalink":"/publication/datnet-tpami/","section":"publication","summary":"We propose a new architecture for addressing sequence labeling, termed Dual Adversarial Transfer Network (DATNet). Specifically, the proposed DATNet includes two variants, i.e., DATNet-F and DATNet-P, which are proposed to explore effective feature fusion between high and low resource. To address the noisy and imbalanced training data, we propose a novel Generalized Resource-Adversarial Discriminator (GRAD) and adopt adversarial training to boost model generalization. We investigate the effects of different components of DATNet across different domains and languages, and show that significant improvement can be obtained especially for low-resource data. Without augmenting any additional hand-crafted features, we achieve state-of-the-art performances on CoNLL, Twitter, PTB-WSJ, OntoNotes and Universal Dependencies with three popular sequence labeling tasks, i.e. Named entity recognition (NER), Part-of-Speech (POS) Tagging and Chunking.","tags":null,"title":"Dual Adversarial Transfer for Sequence Labeling","type":"publication"},{"authors":["Joey Tianyi Zhou*","Hao Zhang*","Di Jing","Hongyuan Zhu","Rick Siow Mong Goh","Kenneth Kwok"],"categories":null,"content":"","date":1564444800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564444800,"objectID":"71993f2b05043b69c161f86249fe19cb","permalink":"/publication/datnet/","publishdate":"2019-07-30T00:00:00Z","relpermalink":"/publication/datnet/","section":"publication","summary":"We propose a new neural transfer method termed Dual Adversarial Transfer Network (DATNet) for addressing low-resource Named Entity Recognition (NER). Specifically, two variants of DATNet, i.e., DATNet-F and DATNet-P, are investigated to explore effective feature fusion between high and low resource. To address the noisy and imbalanced training data, we propose a novel Generalized Resource-Adversarial Discriminator (GRAD). Additionally, adversarial training is adopted to boost model generalization. In experiments, we examine the effects of different components in DATNet across domains and languages, and show that significant improvement can be obtained especially for low-resource data, without augmenting any additional hand-crafted features and pre-trained language model.","tags":null,"title":"Dual Adversarial Neural Transfer for Low-resource Named Entity Recognition","type":"publication"},{"authors":["Joey Tianyi Zhou*","Hao Zhang*","Di Jing","Xi Peng","Yang Xiao","Zhiguo Cao"],"categories":null,"content":"","date":1554508800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554508800,"objectID":"a6ed9b952915cda58369c5d7c175fc14","permalink":"/publication/roseq/","publishdate":"2019-04-06T00:00:00Z","relpermalink":"/publication/roseq/","section":"publication","summary":"In this paper, we mainly investigate two issues for sequence labeling, namely label imbalance and noisy data which are commonly seen in the scenario of Named Entity Recognition and are largely ignored in existing works. To address these two issues, a new  method termed robust sequence labeling (RoSeq) is proposed. Specifically, to handle the label imbalance issue, we first incorporate label statistics in a novel CRF loss. Additionally, we design an additional loss to reduce the weights of overwhelming easy tokens for augmenting the CRF loss. To address the noisy training data, we adopt an adversarial training strategy to improve model generalization. In experiments, the proposed RoSeq achieves state-of-the-art performances on CoNLL and English Twitter NER benchmark datasets without using additional data.","tags":null,"title":"RoSeq: Robust Sequence Labeling","type":"publication"},{"authors":["Joey Tianyi Zhou","Meng Fang","Hao Zhang","Chen Gong","Xi Peng","Zhiguo Cao","Rick Siow Mong Goh"],"categories":null,"content":"","date":1547078400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547078400,"objectID":"ca78f002450f9fba205ffdc6d4dfaa91","permalink":"/publication/lavd/","publishdate":"2019-01-10T00:00:00Z","relpermalink":"/publication/lavd/","section":"publication","summary":"In this paper, we study a new problem in the scenario of sequences labeling. To be exact, we consider that the training data are with annotation of various degrees, namely, fully labeled, unlabeled, and partially labeled sequences. The learning with fully un-/labeled sequence refers to the standard setting in traditional un-/supervised learning, and the proposed partially labeling specifies the subject that the element does not belong to. The partially labeled data are cheaper to obtain compared with the fully labeled data though it is less informative, especially, when the tasks require a lot of domain knowledge. To solve such a practical challenge, we propose a novel deep Conditional Random Field (CRF) model which utilizes an end-to-end learning manner to smoothly handle fully/un-/partially labeled sequences within a unified framework. To the best of our knowledge, this could be one of the first works to utilize the partially labeled instance for sequence labeling and the proposed algorithm unifies the deep learning and CRF in an end-to-end framework. Extensive experiments show that our method achieves state-of-the-art performance in two sequence labeling tasks on some popular data sets.","tags":null,"title":"Learning With Annotation of Various Degrees","type":"publication"},{"authors":null,"categories":null,"content":"Commonsense knowledge bases (KBs) are needed for inference in AI, in contexts such as natural language understanding, image and visual scene understanding, decision-making, etc. For tasks involving real-time interaction and decision-making, especially, the speed of such inference can be critical.\nThe goal of PrimeNet is to set out a framework for a commonsense KB that allows for efficient processing, in order to meet the demands of commonsense reasoning and, hence, support intelligent machine performance in real-world tasks. At the same time, the PrimeNet still provide access to a vast knowledge resource of concepts involving specific object instances.\n","date":1547078400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547078400,"objectID":"d520343040c07db8a23715823bb1a2e4","permalink":"/project/primenet/","publishdate":"2019-01-10T00:00:00Z","relpermalink":"/project/primenet/","section":"project","summary":"A human-inspired framework for commonsense knowledge representation and reasoning.","tags":null,"title":"PrimeNet: Human-inspired Framework for Commonsense Knowledge Representation and Reasoning","type":"project"},{"authors":["Huminski Aliaksandr","Hao Zhang"],"categories":null,"content":"","date":1525132800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525132800,"objectID":"dfa85e97818d1c5f70ba22fce818e735","permalink":"/publication/action-hierarchy/","publishdate":"2018-05-01T00:00:00Z","relpermalink":"/publication/action-hierarchy/","section":"publication","summary":"Modeling action as an important topic in robotics and human-computer communication assumes by default examining a large set of actions as described by natural language. We offer a procedure for how to extract actions from WordNet. It is based on the analysis of the whole set of verbs and includes 5 steps for implementation. The result is not just a set of extracted actions but a hierarchical structure. In the second part of the article, we describe how an action hierarchy can give an additional benefit in a representation of actions, in particular how it can improve an action representation through semantic roles.","tags":null,"title":"Action Hierarchy Extraction and its Application","type":"publication"},{"authors":null,"categories":null,"content":"Current video surveillance systems still require users to monitor an array of video streams from a myraid of cameras to pick out potential threats and other events of interest. Attemps to automate the process typically rely on hand-crafted rules which cannot handle dynamic, uncertain and comples siturations requiring new hand-crafted rules to address each and every new situation. In this project, we apply and extend behavioural learning and commonsense reasoning to video data analysis, which allow video surveillance systems to learn new behaviours without the need to hand craft rules, and to use the learnt behaviours to perform behavioural reasoning in order to predict downstream behaviours and recommend courses of action, and to generate narrative descriptions of visual scenes containing previously learnt behaviours.\nThe objective of the project, named MARACANA, is to develop technology components that can analyze and narrate real world events captured in video, and demonstrate these capabilities in a static surveillance scenario. The technology will provide the human user with a rapid understanding of the happenings in an environment. Generally, we focus on addressing the following issues:\n Develop components that are not built-in to work on only specific scenarios but are adaptive to various scenarios. Knowledge learnt in one scenario should also be transferrable to other scenarios to effect faster learning. Description of the events happening in the real world is in the form of textual natural language.  In order to tackle those problems, several technology components, including event / activity recognition and tracking, behaviour extraction, behavioural (causal) learning, commonsense reasoning/learning, behavioural (causal) reasoning and narrative scene description, are developed and then integrated to form the whole system. The general architecture is shown in the figure below, it briefly illustrates the overall workflow for training and opration processes.\n","date":1524182400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524182400,"objectID":"db9ad1d5edab76f5d2b027393490ccff","permalink":"/project/maracana/","publishdate":"2018-04-20T00:00:00Z","relpermalink":"/project/maracana/","section":"project","summary":"An effectively and flexibly multimodal system to analyze and narrate real world events captured in video.","tags":null,"title":"MARACANA: Behavioural Understanding and Narrative Descriptions from Videos","type":"project"},{"authors":null,"categories":null,"content":"Sequence labeling is a type of pattern recognition task that involves the algorithmic assignment of a categorical label to each member of a sequence of observed values. It includes but not limit to Part Of Speech (POS) tagging, Chunking, Named Entity Recognition (NER), Semantic Role Labeling (SRL) and Punctuation Restoration. Those tasks can be treated as the pre-processing for various natural language processing tasks, which are capable of providing aplenty syntatic or semantic information and greatly improving the performance of subsequent tasks.\nIn this project, we investigated a unified neural network architecture and learning algorithm that can be applied to various sequence labeling tasks including Part of Speech (POS) Tagging, Chunking, Named Entity Recognition (NER) and so on. The aim of this project is to build an effective and versatile module that is able to learn and performance well among various seqeuence labeling datasets without exploiting man-made input features, carefully tuning parameters or setting up different model structures. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge.\nWe did experiments on different publicly available sequence labeling datasets, like CoNLL2002 shared task dataset , CoNLL2003 shared task dataset , IWSLT dataset , Europeana Newspapers dataset and etc., which include POS tagging, chunking, NER and Punctuation Restoration tasks, and achieve convincing results, which are comparable or better than the the state-of-the-arts with carefully hyperparameters tuning and configuration modifying.\nGenerally, our model follows the structure of BiRNN-CNNs-CRF with some modifications, as well as additional and optional modules, such as highway network, attention mechanism and residual connections. For example, we use the four layers structure for Punctuation Restoration task, which contains character-level CNN and word embeddings with highway layer for optimization (1st layer), 4-layer densely conntected bidirectional LSTM network to encode past and future contextual information for feature representations (2nd layer), unidirectional LSTM layer with attention mechanism to learn more informative and contextual feature representations (3rd layer) and a conditional random field (CRF) layer to decode the outputs (4th layer).\nDetails and source codes: IsaacChanghau/neural_sequence_labeling .\n","date":1519084800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1519084800,"objectID":"53cd4d969b7e227da65263dab1b7273a","permalink":"/project/seqlabeling/","publishdate":"2018-02-20T00:00:00Z","relpermalink":"/project/seqlabeling/","section":"project","summary":"An unified and accurate deep learning based approach for various sequence labeling tasks such as POS, Chunking, NER, SRL and Punctuation Restoration.","tags":null,"title":"Neural Sequence Labeling","type":"project"},{"authors":["Huminski Aliaksandr","Hao Zhang"],"categories":null,"content":"","date":1515369600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515369600,"objectID":"5a40e3ae7c0838639957b5daec5f55f3","permalink":"/publication/wordnet/","publishdate":"2018-01-08T00:00:00Z","relpermalink":"/publication/wordnet/","section":"publication","summary":"Commonsense knowledge bases need to have relations that allow to predict the consequences of specific actions (say, if John stabbed Peter, Peter might be killed) and to unfold the possible actions for the specific results (Peter was killed. It could happen because of poisoning, stabbing, shooting, etc.) This kind of causal relations are established between manner verbs and result verbs: manner-result relations. We offer a procedure on how to extract manner-result relations from WordNet through the analysis of the troponym glosses. The procedure of extraction includes three steps and the results are based on the analysis of the whole set of verbs in WordNet.","tags":null,"title":"WordNet Troponymy and Extraction of Manner-Result Relations","type":"publication"},{"authors":null,"categories":null,"content":"Supervisor: Lap Pui Chau\nUnderwater vision enhancement via backscatter removing is widely used in ocean engineering. However, due to the existence of dust-like particles and light attenuation, underwater images and videos always suffer from the problems of low contrast and color distortion.\nIn this project, we investigated the underwater light propagation process from a physical standpoint, studied the state-of-the-art methods of sloving the problem and finally proposed a novel and effective method based on underwater optical model and fusion technique to overcome the backscatter problem.\nIn general, state-of-the-art strategies to solve this issue can be categorized into two parts, one is physical-based model, which studys its physical process and then reverse derivation, while another is more focus on image processing techniques. Experiment shows that carefully designed physical-based models often achieve excellent in specific situations, but are not able to generate great results for varieties of underwater environments all the time. By contrast, image processing methods are more flexiable and perform good under various environments, although they cannot always guarantee to give good contrast and texture information.\nIn order to solve the underwater imaging issue well and also take the universality of the model into consideration, we investigated to incorporate the merits of both physical-based model and image processing model, while suppress their drawbacks at the same time. Hence, we came up with a new technique which utilize a novel fusion strategy to fuse the restored results from physical mdoel and image processing model. Our proposed method is mainly consist of three steps:\n We decomposed the input image into two components, reflectance channel and illuminance channel; We utilized color correction technology and dehazing technology to handle these two components separately; Finally, in order to rebuild result well, we applied the Gaussian and Laplacian pyramids based multi-scale fusion to reconstruct the target image while exposedness, saliency maps are utilized as weights to assist the fusion task.  The experimental results show that the proposed method is able to greatly improve the quality of distorted underwater images. By introducing the underwater image quality metric measurements, we also analyze the intrinsic information and objective feature indexes of restored images via different methods. In general, our method outperforms state-of-the-arts among sets of test images captured in different water environments and is demonstrated to be well-performed and effective. ","date":1471305600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471305600,"objectID":"4f3758beffbbcb7eea4188933786427d","permalink":"/project/backscatter/","publishdate":"2016-08-16T00:00:00Z","relpermalink":"/project/backscatter/","section":"project","summary":"A novel and effective method based on underwater optical model for underwater object visibility enhancement.","tags":null,"title":"Removing Backscatter to Enhance the Visibility of Underwater Object","type":"project"},{"authors":["Hao Zhang","Lap Pui Chau"],"categories":null,"content":"","date":1471305600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471305600,"objectID":"e79ed7dd13f21e5955b5a07181e61c0e","permalink":"/publication/backscatter/","publishdate":"2016-08-16T00:00:00Z","relpermalink":"/publication/backscatter/","section":"publication","summary":"Underwater vision enhancement via backscatter removing is widely used in ocean engineering. With increasing ocean exploration, underwater image processing has drawn more and more attention due to the important roles of video and image for obtain information. However, due to the existence of dust-like particles and light attenuation, underwater images and videos always suffer from the problems of low contrast and color distortion. In this thesis, we analyze the underwater light propagation process and propose an effective method to overcome the backscatter problem. Our method is based on the underwater optical model and image fusion. It mainly contains three steps, first, we decompose input image into reflectance and illuminance components; second, we utilize color correction technology and dehazing technology to handle these two components separately; finally, in order to rebuild result well, we applied the Gaussian and Laplacian pyramids based multi-scale fusion to reconstruct the target image while exposedness, saliency maps are utilized as weights to assist the fusion task. The experimental results show that our proposed method is able to greatly improve the quality of distorted underwater images. By introducing the underwater image quality metric measurements, we also analyze the intrinsic information and objective feature indexes of restored images via different methods. In general, our proposed method outperforms state of the art among sets of test images captured in different water environments and is demonstrated to be well-performed and effective.","tags":null,"title":"Removing Backscatter to Enhance the Visibility of Underwater Object","type":"publication"},{"authors":null,"categories":null,"content":"Supervisor: Hongyu Wang\nThe task of image enhancement is focus on restoring and clarifying the corrupted images to improve their quality, and image enhancement methods has been widely applied to numerous image analysis techniques including pattern recognition, image fusion, image segmentation, image compression and so forth. Among variety of image enhancement methods, algorithms based on Retinex theory have received more and more attentions and have been commonly used in many applications.\nIn this project, we described a Retinex theory based method for contrast and illuminance enhancement in images of low light or unevenly illuminated scenes. This method firstly transforms image from RGB color space to HSV color space, and decomposes the value channel using dual-tree complex wavelet transform. Then, an improved adaptive local tone mapping method is used to process the low frequency component of the image, and wavelet shrinkage method and fuzzy enhancement method are applied to denoise and enhance the high frequency component of the image. After that, the enhanced value channel is reconstructed and a statistical histogram optimization method is used. Finally, the enhanced image is transformed back to RGB color space.\nIn order to verify the feasibility and effectiveness of this method in image enhancement, this paper introduces different image quality assessment criterion, and conducts a great deal of experiments run by MATLAB, and compares against related image enhancement methods proposed by other scholars. Experiment results show that the method proposed by this paper performs very well with enhancement and denoise of the corrupted images. Above shows the performance of proposed method (the last one), other state-of-the-arts and base-line methods. Left side shows the general performance while the right sides give details about local texture information restoration.\n","date":1430438400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430438400,"objectID":"c5512a43d49522bbad238cc423ce8e48","permalink":"/project/retinex/","publishdate":"2015-05-01T00:00:00Z","relpermalink":"/project/retinex/","section":"project","summary":"An improved and effective method for image enhancement based on retinex theory and dual-tree complex wavelet transform techniques.","tags":null,"title":"Image Enhancement based on Retinex Theory and Dual-tree Complex Wavelet Transform","type":"project"}]